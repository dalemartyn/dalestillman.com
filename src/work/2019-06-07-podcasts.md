---
title: "Podcasts"
date: 2020-06-06T12:00:00+01:00
tagline: "A single page web app built with React and Netlify functions."
image:
  json: /podcasts/podcasts-tablet.json
color_light: "#00BCD4"
color_dark: "#00ACC1"
---

I created this [Podcasts][1] web app as an excuse to build something with React. And a single-page app architecture makes sense for a podcast app, to allow media to play as you browse.

## Managing the app state with reducers

The app uses React Router v6 for navigation, which has a new React Hooks-based API which is really nice to work with. I used React's in-built reducers (`useReducer`) along with the Context API to manage the app state. React's reducers work similarly to Redux, but are guaranteed to have forward compatibility with the upcoming Suspense API and Concurrent Mode. [Dan Abramov's two egghead.io courses][2] on Redux are an excellent resource for learning how reducers work.

<figure>
  <div class="c-image-background u-rounded">
    {% image "/podcasts/podcasts-home-page.json" %}
  </div>
</figure>

## Parsing RSS feeds with Netlify functions

For the backend I used Netlify functions, which run on AWS lambda. This allows the app to read RSS feeds without running into cross-origin issues. To improve performance, I used an RSS parser that supports streams. This allows me the first 30 episodes from the RSS feed without downloading the whole feed, making feeds load in seconds â€“ even for feeds over 5MB in size, such as [Javascript Jabber][4].

<figure>
  <div class="c-image-background u-rounded">
    {% image "/podcasts/podcasts-category-page.json" %}
  </div>
</figure>

## Syncing the audio element with the app state

One of the trickiest parts was working around the "[impedance mismatch][5]" between the React programming model and the browser's native [audio element][6]. I initially wanted to have the audio element be driven by the app state, however, the element can also be controlled by the browser. Media playback can be controlled with function keys on keyboards or though phone lock screens and notifications. A better approach turned out to be to let the audio element take care of its own state, and use event listeners to keep the app state, and therefore the UI, up to date. To do this, I had to be able to call the `play()` and `pause()` methods on the audio element from anywhere in the app. I made the audio element available globally using `useRef` with the Context API.

- [Podcasts app][1]
- [Github repo][2]

[1]: https://podcasts.dalestillman.com "Podcasts by Dale"
[2]: https://github.com/dalemartyn/podcast-player "Podcast Player on Github"
[3]: https://egghead.io/instructors/dan-abramov
[4]: https://podcasts.dalestillman.com/podcast?rss=https%3A%2F%2Ffeeds.feedwrench.com%2Fjs-jabber.rss "Javascript Jabber on Podcasts"
[5]: https://overreacted.io/making-setinterval-declarative-with-react-hooks/#the-impedance-mismatch
[6]: https://developer.mozilla.org/en-US/docs/Web/HTML/Element/audio
